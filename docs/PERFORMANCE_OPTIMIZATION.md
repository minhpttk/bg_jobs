# Performance Optimization Guide

## V·∫•n ƒë·ªÅ N+1 Query v√† Gi·∫£i ph√°p

### üîç **V·∫•n ƒë·ªÅ ƒë√£ ph√°t hi·ªán**

V·ªõi dataset l·ªõn (1M+ jobs, >1M tasks), c√°c query patterns hi·ªán t·∫°i g√¢y ra v·∫•n ƒë·ªÅ N+1:

1. **GetJob method**: 2 queries ri√™ng bi·ªát cho count v√† data
2. **RecoverRunningTasks**: N queries cho task updates + N queries cho job updates
3. **Indexes kh√¥ng t·ªëi ∆∞u**: Thi·∫øu covering indexes v√† composite indexes

### ‚úÖ **Gi·∫£i ph√°p ƒë√£ tri·ªÉn khai**

#### 1. **T·ªëi ∆∞u Indexes (Migration 003)**

```sql
-- Covering index cho user/workspace queries
CREATE INDEX idx_jobs_user_workspace_status ON jobs (
    user_id, workspace_id, status, is_deleted
) WHERE is_deleted = false;

-- Covering index cho status/type v·ªõi pagination
CREATE INDEX idx_jobs_status_type_pagination ON jobs (
    status, type, created_at DESC, is_deleted
) WHERE is_deleted = false;

-- Index cho recovery queries
CREATE INDEX idx_tasks_status_recovery ON tasks (
    status, is_deleted, created_at
) WHERE status = 'running' AND is_deleted = false;

-- Covering index cho task queries v·ªõi pagination
CREATE INDEX idx_tasks_job_id_status_pagination ON tasks (
    job_id, status, created_at DESC, is_deleted
) WHERE is_deleted = false;
```

#### 2. **Batch Operations thay v√¨ N+1**

**Tr∆∞·ªõc (N+1 queries):**
```go
// N queries cho task updates
for _, task := range runningTasks {
    s.db.GORM.Model(&models.Tasks{}).
        Where("id = ?", task.ID).
        Updates(...)
}

// N queries cho job updates  
for jobID := range jobIDs {
    s.db.GORM.Model(&models.Jobs{}).
        Where("id = ?", jobID).
        Updates(...)
}
```

**Sau (2 queries):**
```go
// 1 query cho batch task updates
s.db.GORM.Model(&models.Tasks{}).
    Where("id IN ?", taskIDs).
    Updates(...)

// 1 query cho batch job updates
s.db.GORM.Model(&models.Jobs{}).
    Where("id IN ?", jobIDList).
    Updates(...)
```

#### 3. **Single Query v·ªõi Window Function**

**Tr∆∞·ªõc (2 queries):**
```go
// Query 1: Count
s.db.GORM.Model(&models.Tasks{}).Where(...).Count(&count)

// Query 2: Data
s.db.GORM.Where(...).Offset(...).Limit(...).Find(&tasks)
```

**Sau (1 query):**
```sql
WITH task_data AS (
    SELECT *,
           COUNT(*) OVER() as total_count
    FROM tasks 
    WHERE job_id = ? AND is_deleted = false
    ORDER BY created_at DESC
    LIMIT ? OFFSET ?
)
SELECT * FROM task_data
```

### üìä **Performance Improvements**

| Scenario | Tr∆∞·ªõc | Sau | Improvement |
|----------|-------|-----|-------------|
| 1M tasks recovery | ~2M queries | 2 queries | **99.9%** |
| GetJob v·ªõi pagination | 2 queries | 1 query | **50%** |
| Index scan efficiency | O(n) | O(log n) | **Exponential** |

### üöÄ **Best Practices**

#### 1. **S·ª≠ d·ª•ng Batch Operations**
```go
// ‚úÖ T·ªët: Batch update
func (s *TasksService) BulkUpdateTaskStatuses(taskIDs []uuid.UUID, status models.TaskStatus) error {
    return s.db.GORM.Model(&models.Tasks{}).
        Where("id IN ?", taskIDs).
        Updates(map[string]interface{}{
            "status": status,
            "updated_at": time.Now(),
        }).Error
}

// ‚ùå X·∫•u: Individual updates
for _, taskID := range taskIDs {
    s.db.GORM.Model(&models.Tasks{}).Where("id = ?", taskID).Updates(...)
}
```

#### 2. **Covering Indexes**
```sql
-- ‚úÖ T·ªët: Covering index v·ªõi t·∫•t c·∫£ columns c·∫ßn thi·∫øt
CREATE INDEX idx_tasks_job_id_status_pagination ON tasks (
    job_id, status, created_at DESC, is_deleted
) WHERE is_deleted = false;

-- ‚ùå X·∫•u: Index kh√¥ng covering
CREATE INDEX idx_tasks_job_id ON tasks (job_id);
```

#### 3. **Window Functions cho Pagination**
```sql
-- ‚úÖ T·ªët: Single query v·ªõi count
WITH task_data AS (
    SELECT *, COUNT(*) OVER() as total_count
    FROM tasks 
    WHERE job_id = ? AND is_deleted = false
    ORDER BY created_at DESC
    LIMIT ? OFFSET ?
)
SELECT * FROM task_data

-- ‚ùå X·∫•u: Separate count and data queries
SELECT COUNT(*) FROM tasks WHERE job_id = ?;
SELECT * FROM tasks WHERE job_id = ? LIMIT ? OFFSET ?;
```

### üîß **Monitoring v√† Maintenance**

#### 1. **Query Performance Monitoring**
```sql
-- Ki·ªÉm tra index usage
SELECT schemaname, tablename, indexname, idx_scan, idx_tup_read, idx_tup_fetch
FROM pg_stat_user_indexes
WHERE tablename IN ('jobs', 'tasks')
ORDER BY idx_scan DESC;

-- Ki·ªÉm tra slow queries
SELECT query, calls, total_time, mean_time
FROM pg_stat_statements
WHERE query LIKE '%tasks%' OR query LIKE '%jobs%'
ORDER BY mean_time DESC
LIMIT 10;
```

#### 2. **Index Maintenance**
```sql
-- Rebuild indexes ƒë·ªãnh k·ª≥
REINDEX INDEX CONCURRENTLY idx_tasks_job_id_status_pagination;
REINDEX INDEX CONCURRENTLY idx_jobs_user_workspace_status;

-- Analyze tables
ANALYZE jobs;
ANALYZE tasks;
```

### üìà **Expected Performance v·ªõi 1M+ Records**

| Operation | Records | Tr∆∞·ªõc | Sau | Time Saved |
|-----------|---------|-------|-----|------------|
| Task Recovery | 10K tasks | ~20s | ~0.2s | **99%** |
| GetJob pagination | 100K tasks | ~5s | ~0.1s | **98%** |
| Bulk status update | 50K tasks | ~50s | ~0.5s | **99%** |

### üéØ **Next Steps**

1. **Deploy migration 003** ƒë·ªÉ apply optimized indexes
2. **Monitor query performance** sau khi deploy
3. **Implement caching** cho frequently accessed data
4. **Consider read replicas** cho read-heavy operations
5. **Implement connection pooling** n·∫øu ch∆∞a c√≥